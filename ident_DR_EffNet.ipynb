{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "# from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "n_classes = 5\n",
    "input_shape = 512, 512, 3\n",
    "\n",
    "trainLabels = pd.read_csv(\"/Volumes/surya/aptos2019-blindness-detection/train.csv\")\n",
    "trainLabels.head()\n",
    "\n",
    "img_rows, img_cols = 512, 512\n",
    "from skimage import color\n",
    "path = 'Volumes/surya/aptos2019-blindness-detection/train_images/'\n",
    "immatrix = []\n",
    "imlabel = []\n",
    "dirs = [l for l in os.listdir(path) if l != '.DS_Store']\n",
    "total = 0\n",
    "for item in dirs:\n",
    "    base = os.path.basename(path + item)\n",
    "    #print(base)\n",
    "    fileName = os.path.splitext(base)[0]\n",
    "    #print(fileName)\n",
    "    total +=1\n",
    "    #print(dirs)\n",
    "    try:\n",
    "      ls = trainLabels.loc[trainLabels.id_code==fileName, 'diagnosis']\n",
    "      lb = trainLabels.values[ls]\n",
    "      ld = imlabel.append(ls)\n",
    "      print(imlabel)\n",
    "      print(fileName,\" \",total)\n",
    "      import cv2\n",
    "      import glob\n",
    "      import imageio\n",
    "      from skimage.color import rgb2gray\n",
    "      #imgs = glob.glob('/content/train_images/*.png')\n",
    "      # for i in imgs:\n",
    "      #   img = cv2.imread(i)\n",
    "      #   resize_img = cv2.resize(img, (512, 512))\n",
    "      #   cv2.imwrite(i, resize_img)\n",
    "      img = cv2.imread(path +item)\n",
    "      resize_img = cv2.resize(img, (512,512))\n",
    "      img_gray = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY)\n",
    "      img_gray.flatten()\n",
    "      cv2.imwrite(\"gray\"+'/Volumes/surya/aptos2019-blindness-detection/train_images/*.png',img_gray)\n",
    "      pixels = img_gray.astype(np.float32)\n",
    "      immatrix.append(pixels)\n",
    "      #plt.imshow(img)\n",
    "    except (IOError,ValueError) as e:\n",
    "      print('could not read the',fileName ,':',e,'hence skipping it.')\n",
    "immatrix = np.asarray(immatrix)\n",
    "imlabel = np.asarray(imlabel)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data,Label = shuffle(immatrix,imlabel, random_state=4)\n",
    "train_data = [data,Label]\n",
    "type(train_data)\n",
    "\n",
    "(X, y) = (train_data[0],train_data[1])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_val /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_val = np_utils.to_categorical(y_val, n_classes)\n",
    "y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "#data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "datagen = ImageDataGenerator(   \n",
    "        rotation_range=10, \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        shear_range=0.15,  \n",
    "        zoom_range=0.1,  \n",
    "        fill_mode='nearest', \n",
    "        horizontal_flip=True)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "train_gen = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "#EfficientNetB0 Model\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import string\n",
    "import collections\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from six.moves import xrange\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras_applications.imagenet_utils import decode_predictions\n",
    "from keras_applications.imagenet_utils import preprocess_input as _preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Reshape, DepthwiseConv2D, Lambda, multiply, add, GlobalAveragePooling2D\n",
    "from keras.layers import Concatenate, SpatialDropout2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import regularizers\n",
    "#from . import get_submodules_from_kwargs\n",
    "import os\n",
    "import math\n",
    "from typing import List\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.utils import get_file, get_source_inputs\n",
    "_KERAS_BACKEND = None\n",
    "_KERAS_LAYERS = None\n",
    "_KERAS_MODELS = None\n",
    "_KERAS_UTILS = None\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras_applications.imagenet_utils import preprocess_input as _preprocess\n",
    "\n",
    "def get_submodules_from_kwargs(kwargs):\n",
    "    backend = kwargs.get('backend', _KERAS_BACKEND)\n",
    "    layers = kwargs.get('layers', _KERAS_LAYERS)\n",
    "    models = kwargs.get('models', _KERAS_MODELS)\n",
    "    utils = kwargs.get('utils', _KERAS_UTILS)\n",
    "    for key in kwargs.keys():\n",
    "        if key not in ['backend', 'layers', 'models', 'utils']:\n",
    "            raise TypeError('Invalid keyword argument: %s', key)\n",
    "    return backend, layers, models, utils\n",
    "\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n",
    "])\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
    "              expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25)\n",
    "]\n",
    "\n",
    "'''\n",
    "BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
    "              expand_ratio=1, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1], se_ratio=0.25)\n",
    "'''\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_swish(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "    def swish(x):\n",
    "        \n",
    "        return x * Activation('sigmoid')(x)\n",
    "    return  swish\n",
    "\n",
    "def round_filters(filters, width_coefficient, depth_divisor):\n",
    "    \"\"\"Round number of filters based on width multiplier.\"\"\"\n",
    "\n",
    "    filters *= width_coefficient\n",
    "    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
    "    new_filters = max(depth_divisor, new_filters)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += depth_divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "def round_repeats(repeats, depth_coefficient):\n",
    "    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "\n",
    "    return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "def mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', ):\n",
    "    \"\"\"Mobile Inverted Residual Bottleneck.\"\"\"\n",
    "\n",
    "    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n",
    "    bn_axis = 3 if K.set_image_data_format == 'channels_last' else 1\n",
    "\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = block_args.input_filters * block_args.expand_ratio\n",
    "    if block_args.expand_ratio != 1:\n",
    "        x = Conv2D(filters, 1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                          name=prefix + 'expand_conv')(inputs)\n",
    "        x = BatchNormalization(axis=bn_axis, name=prefix + 'expand_bn')(x)\n",
    "        x = Activation(activation, name=prefix + 'expand_activation')(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    x = DepthwiseConv2D(block_args.kernel_size,\n",
    "                               strides=block_args.strides,\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=prefix + 'dwconv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=prefix + 'bn')(x)\n",
    "    x = Activation(activation, name=prefix + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if has_se:\n",
    "        num_reduced_filters = max(1, int(\n",
    "            block_args.input_filters * block_args.se_ratio\n",
    "        ))\n",
    "        se_tensor = GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)\n",
    "\n",
    "        target_shape = (1, 1, filters)\n",
    "        se_tensor = Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n",
    "        se_tensor = Conv2D(num_reduced_filters, 1,\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_reduce')(se_tensor)\n",
    "        se_tensor = Conv2D(filters, 1,\n",
    "                                  activation='sigmoid',\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_expand')(se_tensor)\n",
    "        x = multiply([x, se_tensor], name=prefix + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    x = Conv2D(block_args.output_filters, 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=prefix + 'project_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n",
    "    if block_args.id_skip and all(\n",
    "            s == 1 for s in block_args.strides\n",
    "    ) and block_args.input_filters == block_args.output_filters:\n",
    "        if drop_rate and (drop_rate > 0):\n",
    "            x = Dropout(drop_rate)(x)\n",
    "        x = add([x, inputs], name=prefix + 'add')\n",
    "\n",
    "    return x\n",
    "\n",
    "def EfficientNet(width_coefficient,\n",
    "                 depth_coefficient,\n",
    "                 default_resolution,\n",
    "                 dropout_rate=0.0,\n",
    "                 drop_connect_rate=0.2,\n",
    "                 depth_divisor=8,\n",
    "                 blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "                 model_name='efficientnet',\n",
    "                 include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=None,\n",
    "                 pooling=None,\n",
    "                 classes=5,\n",
    "                 **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        default_resolution: int, default input image size.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: int.\n",
    "        blocks_args: A list of BlockArgs to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    \"\"\"\n",
    "    global backend, layers, models, keras_utils\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    #input = Input(shape=(img_rows, img_cols, channel,))\n",
    "\n",
    "    img_input = Input(shape=(512, 512, 3,))\n",
    "\n",
    "    bn_axis = 3 if K.set_image_data_format == 'channels_last' else 1\n",
    "    activation = get_swish(**kwargs)\n",
    "\n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = Conv2D(round_filters(32, width_coefficient, depth_divisor), 3,\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation(activation)(x)\n",
    "\n",
    "    # Build blocks\n",
    "    num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n",
    "    block_num = 0\n",
    "    for idx, block_args in enumerate(blocks_args):\n",
    "        assert block_args.num_repeat > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        block_args = block_args._replace(\n",
    "            input_filters=round_filters(block_args.input_filters,\n",
    "                                        width_coefficient, depth_divisor),\n",
    "            output_filters=round_filters(block_args.output_filters,\n",
    "                                         width_coefficient, depth_divisor),\n",
    "            num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n",
    "\n",
    "        # The first block needs to take care of stride and filter size increase.\n",
    "        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "        x = mb_conv_block(x, block_args,\n",
    "                          activation=activation,\n",
    "                          drop_rate=drop_rate,\n",
    "                          prefix='block{}a_'.format(idx + 1))\n",
    "        block_num += 1\n",
    "        if block_args.num_repeat > 1:\n",
    "            # pylint: disable=protected-access\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=block_args.output_filters, strides=[1, 1])\n",
    "            # pylint: enable=protected-access\n",
    "            for bidx in xrange(block_args.num_repeat - 1):\n",
    "                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "                block_prefix = 'block{}{}_'.format(\n",
    "                    idx + 1,\n",
    "                    string.ascii_lowercase[bidx + 1]\n",
    "                )\n",
    "                x = mb_conv_block(x, block_args,\n",
    "                                  activation=activation,\n",
    "                                  drop_rate=drop_rate,\n",
    "                                  prefix=block_prefix)\n",
    "                block_num += 1\n",
    "\n",
    "    # Build top\n",
    "    x = Conv2D(round_filters(512, width_coefficient, depth_divisor), 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    if dropout_rate and dropout_rate > 0:\n",
    "      x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(64, activation='sigmoid')(x)\n",
    "    x = Dense(n_classes, activation='sigmoid', kernel_regularizer=regularizers.l1_l2(0.00))(x)\n",
    "    inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name=model_name)\n",
    "\n",
    "    return model\n",
    "\n",
    "def EfficientNetB0(include_top=True,\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=5,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(1.0, 1.0,512, 0.0,\n",
    "                        model_name='efficientnet-b0',\n",
    "                        include_top=include_top,\n",
    "                        input_tensor=input_tensor, input_shape=input_shape,\n",
    "                        pooling=pooling, classes=classes,\n",
    "                        **kwargs)\n",
    "\n",
    "model_effinet = EfficientNetB0(include_top=True)\n",
    "model_effinet.summary()\n",
    "\n",
    "model_effinet.load_weights(\"Volumes/surya/aptos2019-blindness-detection/weights.effi_1st_leaf.hdf5\")\n",
    "print(\"loaded\")\n",
    "\n",
    "adam=Adam(lr=1e-05, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "# determine Loss function and Optimizer\n",
    "model_effinet.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "model_history_en_aug=  model.fit_generator(train_gen, \n",
    "                              steps_per_epoch=len(x_train)//batch_size, \n",
    "                              epochs=10, verbose=1,\n",
    "                              validation_data = (x_val,y_val))\n",
    "\n",
    "# Score trained model.\n",
    "scores = model_effinet.evaluate(test_generator, verbose=1)\n",
    "print('Test loss {:.4f}, accuracy {:.2f}%'.format(scores[0], scores[1] * 100))\n",
    "\n",
    "model_effinet.save_weights(\"Volumes/surya/aptos2019-blindness-detection/weights.effi_1st_leaf.hdf5\")\n",
    "print(\"loaded\")"
   ]
  }
 ]
}