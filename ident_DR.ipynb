{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd07ee82dc6e25e9567cba1c87242e57fa94581db3960606853cb54a564a3309175",
   "display_name": "Python 3.8.8 64-bit ('Test': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "#import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_classes = 5\n",
    "input_shape = 512,512,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id_code  diagnosis\n",
       "0  000c1434d8d7          2\n",
       "1  001639a390f0          4\n",
       "2  0024cdab0c1e          1\n",
       "3  002c21358ce6          0\n",
       "4  005b95c28852          0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000c1434d8d7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001639a390f0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0024cdab0c1e</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>002c21358ce6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>005b95c28852</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "trainLabels = pd.read_csv(\"/Volumes/surya/aptos2019-blindness-detection/train.csv\")\n",
    "trainLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 512, 512\n",
    "from skimage import color\n",
    "\n",
    "path = '/Volumes/surya/aptos2019-blindness-detection/train_images/'\n",
    "immatrix = []\n",
    "imlabel = []\n",
    "dirs = [l for l in os.listdir(path) if l != '.DS_Store']\n",
    "total = 0\n",
    "for item in dirs:\n",
    "    base = os.path.basename(path + item)\n",
    "    #print(base)\n",
    "    fileName = os.path.splitext(base)[0]\n",
    "    #print(fileName)\n",
    "    total +=1\n",
    "    #print(dirs)\n",
    "    try:\n",
    "      ls = trainLabels.loc[trainLabels.id_code==fileName, 'diagnosis']\n",
    "      lb = trainLabels.values[ls]\n",
    "      ld = imlabel.append(ls)\n",
    "      print(imlabel)\n",
    "      print(fileName,\" \",total)\n",
    "      import cv2\n",
    "      import glob\n",
    "      import imageio\n",
    "      from skimage.color import rgb2gray\n",
    "      #imgs = glob.glob('/content/train_images/*.png')\n",
    "      # for i in imgs:\n",
    "      #   img = cv2.imread(i)\n",
    "      #   resize_img = cv2.resize(img, (512, 512))\n",
    "      #   cv2.imwrite(i, resize_img)\n",
    "      img = cv2.imread(path +item)\n",
    "      resize_img = cv2.resize(img, (512,512))\n",
    "      img_gray = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY)\n",
    "      img_gray.flatten()\n",
    "      cv2.imwrite(\"gray\"+'/Volumes/surya/aptos2019-blindness-detection/train_images/*.png',img_gray)\n",
    "      pixels = img_gray.astype(np.float32)\n",
    "      immatrix.append(pixels)\n",
    "      #plt.imshow(img)\n",
    "    except (IOError,ValueError) as e:\n",
    "      print('could not read the',fileName ,':',e,'hence skipping it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immatrix = np.asarray(immatrix)\n",
    "imlabel = np.asarray(imlabel)\n",
    "\n",
    "batch_size = 16\n",
    "n_classes = 5\n",
    "input_shape = 512, 512, 1\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data,Label = shuffle(immatrix,imlabel, random_state=4)\n",
    "train_data = [data,Label]\n",
    "type(train_data)\n",
    "\n",
    "(X, y) = (train_data[0],train_data[1])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_val /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_val = np_utils.to_categorical(y_val, n_classes)\n",
    "y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "#data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "datagen = ImageDataGenerator(   \n",
    "        rotation_range=10, \n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,  \n",
    "        shear_range=0.15,  \n",
    "        zoom_range=0.1,  \n",
    "        fill_mode='nearest', \n",
    "        horizontal_flip=True)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "train_gen = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "#DenseNet Model\n",
    "\n",
    "import keras\n",
    "from keras_applications.densenet import DenseNet121\n",
    "from keras.layers import *\n",
    "from keras import regularizers\n",
    "model = DenseNet121(include_top = False,\n",
    "                    input_shape= input_shape,\n",
    "                  weights=None,\n",
    "                  backend=keras.backend,\n",
    "                  layers=keras.layers,\n",
    "                  models=keras.models,\n",
    "                  utils=keras.utils)\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x =Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(0.01))(x)\n",
    "out = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "from keras import Model\n",
    "model=Model(inputs=model.input,outputs=out)\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "adam=Adam(lr=0.00003, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.load_weights(\"weights.den_1st.hdf5\")\n",
    "print(\"loaded\")\n",
    "\n",
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_history_dn_aug = model.fit_generator(train_gen, \n",
    "                              steps_per_epoch=len(x_train)//batch_size, \n",
    "                              epochs=10, verbose=1,\n",
    "                              validation_data = (x_val,y_val))\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss {:.4f}, accuracy {:.2f}%'.format(scores[0], scores[1] * 100))\n",
    "\n",
    "model.save_weights(\"weights.den_1st.hdf5\")\n",
    "print(\"loaded\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "pred_Y = model.predict(x_test)\n",
    "pred_Y = np.argmax(pred_Y, axis=1)\n",
    "test_Y = np.argmax(y_test, axis=1)\n",
    "print(classification_report(test_Y, pred_Y))\n",
    "\n",
    "cnf_matrix = (confusion_matrix(test_Y, pred_Y))\n",
    "print(\"Confusion matrix \\n\",cnf_matrix)"
   ]
  }
 ]
}